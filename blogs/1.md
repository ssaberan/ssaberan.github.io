# A Bizarre Way Of Evaluating Infinite Series

**Written by: Soroush Saberan**

Given a function $f$ that is infinitely differentiable around a point $a$, we can derive the Taylor expansion of $f$ around $a$ as follows:

$$f(a)=\sum_{n=0}^{\infty}\frac{f^{(n)}(a)}{n!}(x-a)^{n}$$

However, is the reverse also possible to derive? In other words, given an infinite series $S$, can we find a function $f$ such that the Taylor expansion of $f$ around some infinitely differentiable point $a$ is $S$? If this is possible, we might be able to use the resulting function to evaluate $S$.

When investigating this, I decided to use this idea to attempt to solve the famous Basel problem in a new, bizarre way. First proposed in 1650, and solved by Leonhard Euler in 1734[\*](https://en.wikipedia.org/wiki/Basel_problem), the Basel problem asks to evaluate the following:

$$\sum_{n=1}^{\infty}\frac{1}{n^{2}}$$

Lets call this infinite sum $S$. So if we treat $S$ as a Taylor expansion of some unknown function $f$, then we can write each term in $S$ as follows:

$$\frac{1}{n^{2}}=f^{(n-1)}(a)\frac{(x-a)^{n-1}}{(n-1)!} \text{ for } n \in \mathbb{N}$$

Our choice for $x$ and $a$ is arbitrary, so lets choose values that simplify the problem. If we let $x=1$ and $a=0$, we get the following:

$$\frac{1}{n^{2}}=f^{(n-1)}(0)\frac{1}{(n-1)!} \text{ for } n\in \mathbb{N}$$

Rearranging the terms to isolate $f^{(n)}(0)$ gives us:

$$f^{(n)}(0)=\frac{n!}{(n+1)^{2}} \text{ for } n\in \mathbb{N}\cup\{0\}$$

So given the requirement above, what is $f$?

If you take the Taylor expansion of $f$ centered around $x=0$, you get the following:

$$f(x)=\sum_{n=0}^{\infty}\frac{f^{(n)}(0)}{n!}x^{n}$$

Substituting for $f^{(n)}(0)=\frac{n!}{(n+1)^{2}}$ yields:

$$f(x)=\sum_{n=0}^{\infty}\frac{\frac{n!}{(n+1)^{2}}}{n!}x^{n}=\sum_{n=0}^{\infty}\frac{x^{n}}{(n+1)^{2}}$$

Now use the formula, $\sum_{n=0}^{\infty}t^{n}=\frac{1}{1-t}$. We want to manipulate the left side of this equation until it becomes $\sum_{n=0}^{\infty}\frac{x^{n}}{(n+1)^{2}}$. Then whatever is on the right side will be $f$:

$$\sum_{n=0}^{\infty}t^{n}=\frac{1}{1-t}\Rightarrow$$

$$\int_{0}^{x}\sum_{n=0}^{\infty}t^{n}dt=\int_{0}^{x}\frac{1}{1-t}dt\Rightarrow$$

$$\sum_{n=0}^{\infty}\frac{x^{n+1}}{n+1}=-\ln(1-x)\Rightarrow$$

$$\sum_{n=0}^{\infty}\frac{x^{n}}{n+1}=-\frac{\ln(1-x)}{x}\Rightarrow$$

$$\int_{0}^{x}\sum_{n=0}^{\infty}\frac{t^{n}}{n+1}dt=\int_{0}^{x}-\frac{\ln(1-t)}{t}dt\Rightarrow$$

$$\sum_{n=0}^{\infty}\frac{x^{n+1}}{(n+1)^{2}}=-\int_{0}^{x}\frac{\ln(1-t)}{t}dt\Rightarrow$$

$$\sum_{n=0}^{\infty}\frac{x^{n}}{(n+1)^{2}}=-\frac{1}{x}\int_{0}^{x}\frac{\ln(1-t)}{t}dt\Rightarrow$$

So we get that

$$f(x)=-\frac{1}{x}\int_{0}^{x}\frac{\ln(1-t)}{t}dt$$

is the value for $f$ we were looking for.

If we plug $x=1$ into $f(x)=-\frac{1}{x}\int_{0}^{x}\frac{\ln(1-t)}{t}dt$, we get:

$f(1) = -\int_{0}^{1}\frac{\ln(1-t)}{t}dt$.

Let the integral be $J = \int_{0}^{1}\frac{\ln(1-t)}{t}dt$.

To evaluate $J$, we can use the Taylor series expansion for $\ln(1-t)$, which is $\ln(1-t) = -\sum_{k=1}^{\infty} \frac{t^k}{k}$, valid for $|t|<1$.

Substituting this into the integral:

$$J = \int_{0}^{1} \frac{1}{t} \left(-\sum_{k=1}^{\infty} \frac{t^k}{k}\right) dt = -\sum_{k=1}^{\infty} \int_{0}^{1} \frac{t^{k-1}}{k} dt$$

Assuming that we can interchange the summation and integration (this can be justified by results such as the Monotone Convergence Theorem, or by considering integration over $[0, 1-\epsilon]$ and taking the limit as $\epsilon \to 0^+$), we evaluate the integral:

$$J = -\sum_{k=1}^{\infty} \left[\frac{t^k}{k^2}\right]_{t=0}^{t=1} = -\sum_{k=1}^{\infty} \left(\frac{1^k}{k^2} - \frac{0^k}{k^2}\right) = -\sum_{k=1}^{\infty} \frac{1}{k^2}$$

The sum $\sum_{k=1}^{\infty} \frac{1}{k^2}$ is the value of the Riemann zeta function at $s=2$, commonly denoted as $\zeta(2)$.

The value of $\zeta(2)$ can be determined by using Fourier series analysis. One common approach involves finding the Fourier series representation of a simple polynomial function and then evaluating it at a specific point.

Consider the function $g(x)=x^2$ defined on the interval $[-\pi, \pi]$. The Fourier series of $g(x)$ is given by:

$$g(x) = \frac{a_0}{2} + \sum_{n=1}^{\infty} (a_n \cos(nx) + b_n \sin(nx))$$

Since $g(x)=x^2$ is an even function, all $b_n$ coefficients are zero.

The coefficient $a_0$ is:

$$a_0 = \frac{1}{\pi}\int_{-\pi}^{\pi} x^2 dx = \frac{1}{\pi}\left[\frac{x^3}{3}\right]_{-\pi}^{\pi} = \frac{1}{\pi}\left(\frac{\pi^3}{3} - \frac{(-\pi)^3}{3}\right) = \frac{2\pi^2}{3}$$

The coefficients $a_n$ for $n \ge 1$ are:

$$a_n = \frac{1}{\pi}\int_{-\pi}^{\pi} x^2 \cos(nx) dx$$

Using integration by parts twice:

$$
\begin{aligned}
\int x^2 \cos(nx) dx &= \frac{x^2 \sin(nx)}{n} - \int \frac{2x \sin(nx)}{n} dx \\
&= \frac{x^2 \sin(nx)}{n} - \left(-\frac{2x \cos(nx)}{n^2} + \int \frac{2\cos(nx)}{n^2} dx\right) \\
&= \frac{x^2 \sin(nx)}{n} + \frac{2x \cos(nx)}{n^2} - \frac{2\sin(nx)}{n^3}
\end{aligned}
$$

Evaluating this from $-\pi$ to $\pi$:

$$a_n = \frac{1}{\pi} \left[\frac{x^2 \sin(nx)}{n} + \frac{2x \cos(nx)}{n^2} - \frac{2\sin(nx)}{n^3}\right]_{-\pi}^{\pi}$$

$$a_n = \frac{1}{\pi} \left( \left(0 + \frac{2\pi \cos(n\pi)}{n^2} - 0\right) - \left(0 + \frac{-2\pi \cos(-n\pi)}{n^2} - 0\right) \right)$$

Since $\cos(n\pi) = (-1)^n$ and $\cos(-n\pi) = \cos(n\pi) = (-1)^n$:$$a_n = \frac{1}{\pi} \left( \frac{2\pi (-1)^n}{n^2} + \frac{2\pi (-1)^n}{n^2} \right) = \frac{4(-1)^n}{n^2}$$

So the Fourier series for $x^2$ on $[-\pi, \pi]$ is:

$$x^2 = \frac{\pi^2}{3} + \sum_{n=1}^{\infty} \frac{4(-1)^n}{n^2} \cos(nx)$$

We can evaluate this series at a specific point, for example $x=\pi$:$$\pi^2 = \frac{\pi^2}{3} + \sum_{n=1}^{\infty} \frac{4(-1)^n}{n^2} \cos(n\pi)$$

Since $\cos(n\pi) = (-1)^n$:

$$\pi^2 = \frac{\pi^2}{3} + \sum_{n=1}^{\infty} \frac{4(-1)^n}{n^2} (-1)^n = \frac{\pi^2}{3} + \sum_{n=1}^{\infty} \frac{4}{n^2}$$

$$\pi^2 = \frac{\pi^2}{3} + 4\sum_{n=1}^{\infty} \frac{1}{n^2}$$

Now, we solve for the sum:

$$\pi^2 - \frac{\pi^2}{3} = 4\sum_{n=1}^{\infty} \frac{1}{n^2}$$

$$\frac{2\pi^2}{3} = 4\sum_{n=1}^{\infty} \frac{1}{n^2}$$

$$\sum_{n=1}^{\infty} \frac{1}{n^2} = \frac{2\pi^2}{12} = \frac{\pi^2}{6}$$

So, $\zeta(2) = \frac{\pi^2}{6}$.

Substituting this back into our expression for $J$:

$$J = -\sum_{k=1}^{\infty} \frac{1}{k^2} = -\zeta(2) = -\frac{\pi^2}{6}$$

Therefore,

$$f(1) = -(-\frac{\pi^{2}}{6}) = \frac{\pi^{2}}{6}$$

This matches the famous result by Leonhard Euler!
